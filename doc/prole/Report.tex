\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{array}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{fancyhdr}
\usepackage{tikz}
\usepackage{float}
\usepackage{listings}
\usepackage{color}
\usepackage{caption}
\usepackage{longtable}
\usepackage[nottoc]{tocbibind}
\usepackage[cache=false,section]{minted}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage[ruled]{algorithm2e}
\usepackage{glossaries}
\usemintedstyle{default}
\newminted{haskell}{frame=lines,framerule=2pt}
\newminted{R}{frame=lines,framerule=2pt}
\graphicspath{{./images/}}

\tikzstyle{bag} = [align=center]

\makeglossaries

\newacronym{dp}{DP}{Dynamic Pipeline Paradigm}
\newacronym{bfs}{BFS}{Breadth-First Search}
\newacronym{dfs}{DFS}{Depth-First Search}
\newacronym{wcc}{WCC}{Weak Connected Components}
\newacronym{haskell}{Haskell}{Haskell Programming Language}
\newacronym{fp}{FP}{Functional Programming}

\title{Towards a Haskell Abstraction of Dynamic Pipeline Paradigm}
\author{
\begin{tabular}{c c}       
      Juan Pablo Royo Sales & Edelmira Pasarella\\ 
      \small{Universitat Politècnica de Catalunya} & \small{Computer Science Department}\\
      \small{Barcelona - Spain} & \small{Universitat Politècnica de Catalunya}\\ 
      \small{\texttt{juan.pablo.royo@estudiantat.upc.edu}} & \small{Barcelona - Spain}\\ 
      \small{} & \small{\texttt{edelmira@cs.upc.edu}}\\
\end{tabular}
}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{Dynamic Pipeline on Haskell}
\fancyhead[R]{\thepage}
\fancyfoot[L,C]{}
\setlength{\headheight}{15pt}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\newtheorem{hyp}{Hypothesis}
\date{}

\begin{document}

\maketitle
\begin{abstract}
\textit{Dynamic Pipeline Paradigm} has been defined in order to solve problems where the data is heterogeneous 
and in motion. Taking advantage on pipelining stage parallelization, this paradigm allows to dynamically adapt 
stage computations according to the input. It has been shown in the definition of this computational model that any
implementation attempt of the Paradigm requires fast and flexible parallelization techniques as well as tools that 
are suitable with the notion of Computation as a First Class Citizen. In this work we implement \textit{Dynamic Pipeline Paradigm}
using \texttt{Haskell} for \textit{Finding Connected Components of a Graph} as a primary example problem. We show different results 
and how \texttt{Haskell} behaves on that context showing that it is a suitable Language for implementing \textit{Dynamic Pipeline Paradigm} 
not only because its strong theoretical foundations which provides a strong manipulations of Computations as primary entities, but also because it has a powerful 
Set of Tools for writing multithreading and parallel computations with optimal performance.
\end{abstract}

\section{Introduction}
\textit{\acrfull{dp}} has been defined in~\cite{dp_def} along side with some examples problems that are suitable to be solved with this Computational Model.
One of those problems is \textit{Finding Connected Components of an Undirected Graph}, which is known as a \textbf{\acrfull{wcc}} problem. 
Given an Undirected Graph $G = (V, E)$, we can find \acrshort{wcc} of $G$ in $O(V + E)$ using \textit{\acrfull{dfs}} or \textit{\acrfull{bfs}} algorithm~\cite{CormenLeisersonEtAl09}. 
Although this problem can be solved in linear complexity time, when we are manipulating real Graphs, which are usually big, it would be better to have a more suitable Computational Model where this can be done with
optimal performance. \acrshort{dp} with its \textit{Parallelization Pipeline model} improve that performance on Big Graphs for finding \acrshort{wcc}.
One of the biggest challenge of \acrshort{dp} is to find a proper Set of Tools and Language which can take advantage from both: Fast Parallel processing and Strong theoretical foundations that manage computations as First Class Citizens. 
On that sense we conduct with this work an implementation of \acrshort{dp} for solving \acrshort{wcc} with \acrfull{haskell} showing that both aspects are covered.

\textbf{Objective:} We show that \acrshort{haskell} it is a suitable Language for implementing \acrshort{dp} working with the problem of \acrshort{wcc}, in order to further create an Abstraction Library or Framework
to solve other Problems with \acrshort{dp} in \acrshort{haskell}.
In that sense we show the techniques and tools used on the language to achieve the desired goal as well as the measurements taken to empirically show how this solution behave in terms of performance and parallelization.

\textbf{Contributions:} We start to create and define an abstraction of \acrshort{dp} in \acrshort{haskell} which is going to allow use this new tool set for solving other computational problems that fits with this Computational Model.

\section{DP for finding Connected Components}
\textbf{Here we should put the Pseudo Code of DP Connected Components}

\section{Haskell Implementation}
In this section we are going to show all the implementation details for building a \acrshort{dp} Abstraction in \acrshort{haskell} solving \acrshort{wcc} problem.
There are two main components in \acrshort{dp} model which requires a careful choice to succeed in the implementation of the model: Parallelization to support Pipeline Parallel processing without penalizing global computation and Channels to link and communicate 
the different stages of the pipeline. We can argue that another special components is the dynamic generation of the computations or \textit{Filters}, but choosing a \acrfull{fp} Language like \acrshort{haskell} allow us to represent
that for free with \textit{Anamorphism} and \textit{Catamorphisms}~\cite{lenses}.

\subsection{Parallelization}
One of the most important components on this implementation is the selection of \textbf{Concurrency Library} to support an intensive load on parallelism. A direct guess to achieve this
could be to use \textit{Monad Par} based on this work~\cite{monad_par}, but we have discarded that since we want to achieve Parallelism at Thread level and not to Spark level, due to the nature
of \acrshort{dp} where the approach of the model is Pipeline Parallelism and not Data Parallelism. The next obvious choice is to use \mintinline{haskell}{forkIO :: IO () -> IO ThreadId} from \mintinline{bash}{base}
module, but that would imply to handle all the threads lifecycle, terminations and errors in a custom manner. We choose \textbf{async}\footnote{https://hackage.haskell.org/package/async} 
library which allow us to spawn asynchronous computations~\cite{parallel_book} on \acrshort{haskell}.

\subsection{Channels}
The other 


\begin{listing}[H]
\begin{minted}[fontsize=\normalfont,numbers=left,frame=lines,framerule=2pt,framesep=2mm,baselinestretch=1.2,highlightlines={3-3,9-11,17}]{haskell}
    fn = undefined
    \end{minted}
    \caption{Extracted from source code code/Script.R}
    \label{src:haskell:1}
\end{listing}


\section{Experiments and Discussion}
fdasfd

\section{Future Work}
dfads

\section{Conclusions}
dfasfda

\clearpage

\printglossary[type=\acronymtype]

\printglossary

\bibliographystyle{alpha}
\bibliography{Report}

\appendix

\end{document}

