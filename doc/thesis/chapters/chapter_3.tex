\chapter{Related Work}\label{relate-work}
In this chapter, we present \emph{the state of the art} of \acrlong{bt} in \acrlong{bg} and incremental processing.
At the begining we explore some works related to subgraph enumeration problem, since a \acrshort{bt} is a subgraph. Then, in the case of \acrshort{bt} in \acrshort{bg}, we show the last novel work that has been conducted in \acrshort{bt} counting problem,
and in the case of incremental computations, we describe some related researches that has been done lately. 

\section{Subgraph Enumeration}\label{sec:rel-work:subgraph}
\paragraph{Enumerating subgraphs using Map-Reduce} 
Subgraph enumeration problem has been treated here~\cite{enumeratingsg} using a single round map-reduce.
The problem presented on this work is enumerate all instances of a given subgraph (sample graph) in a very big graph using a single map-reduce round. 
In the work all the examples are conducted with the smallest subgraph known which is the triangle.
The solution proposed is presented as a special case of computing a multiway join but improving complexity reducing the communication cost and the computation cost.
For achiving this, the authors present an improvement over the \emph{Partition Algorithm of Suri and Vassilvitskii}~\cite{partitionalgo} replicating all edges the same number of time
reducing the communication cost to conciliate duplicated triangles. In regards to the computation cost an improvement over the \emph{multiway-join} algorithm is proposed using an ordering 
of the buckets node. The main advantages of this work is the use of an stream parallelization model like Map-Reduce bringing the choice to exploit parallel and distributed computation to gain efficiency. 
Moreover, the improvments done by the authors reduce even more the processing time for the enumeration. Another advantage is the use of sample graph for querying specific subgraphs and not all of them, 
as we can see in the \autoref{sec:motivation}, to be able to process very big graphs in an efficient manner when the user does not need the whole results.
The first limitation of this work is the use of an streaming model like Map-Reduce. Although it is a parallel and distributed model, incremental results are not possible until all the reducers are calculated; we can compute in parallel but we cannot produce in parallel.
The other limitation is the adjustment of resources that in this work and due to the map-reduce nature of the model is done statically a priori. The partition needs to be done by the number of nodes and edges that you only know beforehand.
As we have state in \autoref{sec:motivation}, \acrshort{dp} overcome both of these limitations providing a Dynamic Pipeline parallelization model. The first limitation of incrementally generates results is done by the nature of \acrshort{dp} model. 
The other limitation regarding the runtime adjustment of resources is also done by the nature of the model because it does not need to know the structure of the graph beforehand. 

\paragraph{Distributed subgraph matching on timely dataflow} In this work~\cite{Lai} the authors also covers the subgraph matching problem in big graphs using a distributed computational model. 
The main contribution of this work is the optimization of four \emph{state of the art} strategies algorithms use on \mintinline{shell}{Timely} dataflow system~\cite{timelyflow}. 
The sketch of the algorithm relies on randomly partition the vertices using hashing where the neighbors are going to be place in the same partition.
Query vertices are attributes and results are relational tables, enabling the subgraph matching problem to be expressed with natural joins, where the solution is to find the optimal distributed join plan.
The join algorithms improved are $\mathtt{BinJoin}$, $\mathtt{WOptJoin}$ and $\mathtt{ShrCube}$ using the following optimizations techniques: \mintinline{shell}{Batching},\mintinline{shell}{TrIndexing} and \mintinline{shell}{Compression}.
In the case of \mintinline{shell}{Batching} the optimization relies on processing in batch mode the partial results that matches a subset of vertices in a way that each partial result can be batched in a single task to process against the whole result.
\mintinline{shell}{TrIndexing} or Triangle Indexing precomputes triangles of a data graph and indices to prune unfeasible results beforehand. Finally \mintinline{shell}{Compression} maintains intermediate results in a compressed form to reduce communication and 
maintenance. The results obtained on this work are efficient but it always depends on the machine characteristics and the topology of the graph. Some combinations are better with some optimizations techniques if there is a chance for examplle to have on each machine 
all graph in memory, but for example the authors recommend to use always \mintinline{shell}{Compression} and when there is enough space \mintinline{shell}{TrIndexing} to achieve the best results. 
We believe that the main limitations of this work is that although the authors claimed this analysis can be conducted against other distributed tools like Spark~\cite{apachespark} for example, they have conducted all the implementation and benchmarking with
\mintinline{shell}{Timely}~\cite{timelyflow} and uses some of the optimizations that the tool already provide like \mintinline{shell}{HashJoin} for building the pipeline. It is not clear how this would can be replicated to other models.
On a \acrshort{dp} model we offer a model that is unaware of specific tool or implementation. It is an abstract model that allows to build any pipeline parallelization algorithm.
Having saying that, one of the things that we have gathered from this work to implement in our solution is the use of \mintinline{shell}{Compression} as technique for better maintenance and performance both on memory and computation time.


\section{\acrlong{bt} Counting in \acrlong{bg}}\label{sec:rel-work:counting}
The problem of Counting \acrshort{bt} have been deeply addressed in the work of Yang et al.~\cite{btcount} where they present several \emph{polly-time} algorithms to solve it.
In that paper, the authors present different approaches to calculate with a combinatorial algorithmic the counting problem of \acrshort{bt} in \acrshort{bg}. 
They show three algorithms to count all the \acrshort{bt} in the graph \emph{(Global Counting)}, and two algorithms to count only locally \acrshort{bt} \emph{(Local Counting)}: this means that given a vertex or an edge, the algorithms count only the number of \acrshort{bt} in which 
that vertex or edge is participating.

In the case of \emph{Global Counting}, the first algorithm the authors introduced is \emph{wedge-based counting}. We do not cover this because it is discarded
by the authors in the empirical analysis since the complexity is the highest of three and, it did not perform well in the experimentation phase.
The first important algorithm is Super-wedge based algorithm (SWJ-Count) and it relies on \emph{swj-unit} counting, which is a novel concept introduced in this work. A \emph{swj-unit} is a connected subgraph that is formed by two \emph{super-wedges}. A \emph{super-wedge}
is a 3-hop path. The authors shows that a \acrshort{bt} is a \emph{swj-unit} but not every \emph{swj-unit} is a \acrshort{bt}. Those 
are not \acrshort{bt} are \emph{acyclic swj-unit}. The main idea of the algorithm is to count all \emph{swj-unit} and the \emph{acyclic swj-unit}; therefore
the number of \acrshort{bt} can be deduced straightforward.
The main advantage of SWJ-Count compared with the wedge-based is that it does not count wedges twice.
Therefore the complexity is less although both \emph{polly-time}.
In terms of empirical analysis, it performs well up to graphs of $4 \times 10^20$ bi-triangles. After that, the algorithm times out.
The second algorithm they proposed is Ranked Super-wedge based algorithm (RSWJ-Count). This is a better approach compared with the previous in terms of complexity and running time because it takes the same gadget to count which is the \emph{swj-unit} but introducing ranking on the degree of the vertices. The main idea is that vertices with a higher degree have more super-wedges 
and therefore \emph{swj-unit} can be count faster by sharing computations. RSWJ-Count is the best of all three algorithms for doing global counting.
The main limitation of \emph{Global Counting} is that the user needs to wait for the whole calculation to complete and there is no partial result of it.
We have stated previously that \acrshort{dp} model overcomes this limitation by its pipeline parallelization nature having the ability to output partial counts of the graph which is important for doing estimation counting.


Regarding \emph{Local Counting} the work presents two strategies. 
Both algorithms to count locally \acrshort{bt} given a particular vertex or an edge, are based on the previous \emph{swj-unit} global algorithm, but instead of check every vertex, it only calculates from the one that is requested. 
The main advantage of doing \emph{Local Counting} is the ability to reduce processing time when the user does not need to analyze the whole network but just a partial of it, as we have seen in \autoref{sec:motivation}.
The empirical analysis of these local algorithms obtained better results that global counting without any time out on any study case.
The principal limitation of \emph{Local Counting}, apart to share the same limitation of \emph{Global Counting} regarding incremental results, is that it does not have the possibility to reuse previous calculations if 
several vertices or edges search are requested. In this case the algorithm needs to recalculated locally for every edge or vertex request.
Our model improve this limitation taking advantage again with the use of \acrshort{dp} model. In our model the computation of \acrshort{bt} is done once and multiple queries can be processed without need to recalculate again.

\section{Incremental Computation}
The ability to deliver incremental results without waiting for the whole results is known as the \emph{pay-as-you-go} model. This plays a fundamental role in applications that needs to process big data. 
There have been different use cases in which this approach has helped to obtain partial results in large data set structures.

\paragraph{Fact-Checking} Some of these studies are related to \emph{Fact Checking Pay-as-you-go} models~\cite{factcatch} which use incremental quality estimation to provide fact-checking over world wide web documents.
Here, the authors require that it should continuously improve the credibility assessment of the documents in the database and, users may then examine the
that to decide whether to stop or resume validation.
For conducting this model, they propose a simple front-end application connecting with a backend that is communicating with a Database in PostgreSQL. 
The limitations of their model rely on any use of parallelization computation. Basically, they are relying on all the computational models to the Database system. 
We believe that an incremental approach or \emph{pay-as-you-go} model can be described and implemented better with a \acrshort{dp} model because all the processing is done in parallel. 
Another advantage of \acrshort{dp} model is that, once the data is computed, if we are in an unbounded data stream, we can receive more data to incrementally update and deliver results. 
In the case of \emph{fact-checking}, those updates could be new validations.

\paragraph{\emph{motif-paths}} Another important use of this model is found in \emph{motif-paths} work~\cite{Li2019MotifPA} like we discussed on previous \autoref{intro}.
Because of the complexity of building a \emph{motif-graph} to establish the shortest path, this path is search incrementally in an algorithm called \emph{Incremental Motif-path Search (IMS Search)}.
The idea of this algorithm is the following: After all the motif-graphs are discovered around some seed $s$, a motif-path $\mathbf{P}$ can be constructed based on those instances.
The process is repeated until a target $t$ node is discovered. According to the paper, this method has two limitations. First, it is possible to detect \emph{motif-path} that contains 
redundant \emph{motif-instances}. Secondly, the incremental search proposed might be far from the optimal direction. For the first issue, the authors proposed a pre-filter for the \emph{motif-instances},
and for the second one, a bi-directional search allowing to explore different seeds. 
In that sense, \acrshort{dp} can improve this incremental search first because it can provide a special filter for \emph{motif-instances} eliminating the need for filtering because the filter is built-in in the model itself.
Then, to deal with the optimal direction, \acrshort{dp} allows retro-feeding the pipeline more than once with more than one channel. This means that we are not only able to explore different seeds, but we also can do it in parallel as well.

\section{Chapter Summary}
In this chapter, we have summarized all the \emph{State of the Art} that are related to our research.
First, we have shown all the details of the most recent work regarding subgraph enumeration problem. 
After that we analyze the latest and most important work on counting \acrlong{bt} in \acrlong{bg}.
Then, we have also explored, what are the latest research and explorations in the use of incremental computational models (\emph{pay-as-you-go}).
