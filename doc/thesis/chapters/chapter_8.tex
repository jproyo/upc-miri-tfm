\chapter{Conclusions and Future Work}\label{conclusions}
In this chapter, we present the future work that we think it is interesting to address as a result of this research, 
as well as the conclusions obtained.

\section{Future Work}
One of the first things that have been out of the scope of this work and it will be tremendously important to address in order to be able to process huge networks efficiently is 
the selection of better data structures for handling the search in the compress \acrshort{bt} once the query command arrives at the $\ad$.
We have seen in \autoref{sub:sec:res:e3} how there is a memory bottleneck that is not allowing the execution of bigger graphs without paying so much extra cost. 
Performing indexing over the edges and vertices could lead to important improvements in search, although there is a trade-off in terms of memory allocation.
On the other hand, and continuing with the same idea, an important work to be addressed in the future is the distribution of the stages not only between threads but also between machines. 
We believe that moving from a multithreading model to a distributed model will allow \acrlong{dp} to reduce the gap of memory consumption for bigger graphs instances, as well as distribute the stage according to the amount of memory required by them. 
This leads to a similar scenario as before, there is a trade-off in terms of transfer data and the delay that this kind of distributed computation brings, but 
since we are delivering incremental results and we have implemented a \emph{pay-as-you-go} model, the distribution cost could be amortized; without mentioning that the speed up and reliance on network communication is higher than ever.

In another aspect of the computational model and more related with the \acrlong{hs} implementation, there are several improvements to be conducted there as well. One of them could be
to delegate the distribution to other stream processing systems like Kafka~\cite{kafka} for example, and do the parallel processing of the split data with \acrshort{hs} consuming from them.
Moreover, some radical improvements can be done into \acrshort{dpfh}. From designing more abstractions to help the user to write pipelines with less effort and errors, up to helping the thread schedule and memory management to perform even better than it is now. 
One of this speedup could be moving some types to be Unboxed types~\cite{hs-unbox} which reduce memory footprint.

\section{Conclusions}
Dealing with $NP$-complete problems like Enumerating \acrlong{bt} in \acrlong{bg}, is a task that, in general, is addressed using approximation algorithms or heuristics. 
On the other hand, introducing algorithms in a \emph{pay-as-you-go} model approach combined with a model of computation that enables building incremental solutions like \acrshort{dp}, brings exhaustive and exact results for the solution space that the user wants to obtain.    
\acrfull{dp} has shown to be an efficient model for building an Incremental and parallel algorithm to enumerate \acrlong{bt} in \acrlong{bg}. 
In addition to that, we have given a novel solution for the enumeration problem which has not been addressed in any other work at the time of writing this thesis.
Moreover, we have also shown how strong is this paradigm in companion with a powerful language like \acrfull{hs}. The capabilities of combining both not only for implementing the concepts but also for supporting intensive experiments with large size graphs and complex topologies. 
Following that, the designed algorithm \acrshort{dpbt} can process and enumerate big networks like the \acrlong{dbpedia} which contains more than $300$ millions of \acrlong{bt}.
In the experimental analysis, we have demostrated as well, if the implementation delivers incremental results using \acrlong{dm} giving support to our research assumptions and motivations. 

In conclusion, we believe that the achieved results clearly show we have reached the goal on providing an \emph{Incremental Algorithm for Enumerating Bi-triangles on Bi-partite Graphs}, opening a wide range of possibilities not only to improve the existing framework and algorithm but also for implementing other complex problems where the use case requires a \emph{pay-as-you-go} model.
