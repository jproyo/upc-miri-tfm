\section{Preliminaries}\label{prelim}
Before moving forward with the core of the research, we describe the fundamental concepts that support the different parts of our study. That is, the metrics used to capture continuous behavior, pipeline parallelism processing in general, and the dynamic pipeline paradigm. Next, we present an implementation of weakly connected components in Haskell following this paradigm. 
\subsection{Basic Concepts}
%
\subsubsection{Diefficiency Metrics}\label{prem:dief}
In this work, we use two relevant metrics to measure the diefficiency, i.e., continuous efficiency of a program to generate incremental results. The metrics to measure diefficiency are \acrshort{dt} and \acrshort{dk}~\cite{diefpaper}. The metric \acrshort{dt} quantifies the continuous efficiency during the first $t$ time units of execution regarding the results generated by the program. The higher value of the \acrshort{dt} metric, the better the continuous behavior. The metric \acrshort{dk} measures the continuous efficiency while producing the first $k$ answers. The lower the value of the \acrshort{dk} metric, the better the continuous behavior.
Both metrics can be computed using \acrfull{dm} Tool \acrshort{dtkp}\footnote{\url{https://github.com/SDM-TIB/diefpy/}}, given the traces of the execution of each of the approaches.
Additionally, \acrshort{dtkp} generates two different kinds of plots from an execution trace: A bi-dimensional plot  and a radial plot. In the bi-dimensional plot, the x-axis represents the time when answers  are generated and the y-axis represents the number of generated answers. Points  $(x,y)$  are taken from traces.  The radial plot contains the visual comparison of \acrshort{dt} the metric with respects to other non-continuos metrics, such as, 
\begin{inparaenum}[\bf i\upshape)]
  \item \acrfull{comp} which is the total number of  produced answers. 
  \item \acrfull{tfft} which measure the elapsed time spent to produce the first answer. 
  \item \acrfull{et} which measures the elapsed time spent  to complete the execution of a query. 
  \item \acrfull{tt} which measure the number of total answers produced after evaluating a query divided by its execution time \acrshort{et}
\end{inparaenum}.

\subsubsection{\acrfull{pip}} \label{prelim-pip}
A pipeline parallelism approach divides a process computation into sequential stages that are stateful operators~\cite{hr19}. Each stage takes the result of the previous one as an input and downstream its results to the next stage. Each \emph{Pipeline Stage} is parallelized. The communication between stages takes place through some means, typically channels. One of the main advantages of this model is that the stages are non-blocking, i.e., there is no need to wait to process all data to run the next stage. This kind of paradigm enables computational algorithms that can generate incremental results, preventing users wait until the end of the whole data stream processing to get a result. This feature corresponds with the nature of the Dynamic Pipeline Paradigm. Hence, the \acrshort{pip} approach is a proper parallelization streaming computational model for a Dynamic Pipeline Framework implementation. It is worth noting that although pipeline stages are parallelized in the \acrshort{pip} approach,  unbalanced intensive computation in one stage w.r.t. the other ones might delay the whole processing as a natural consequence of the sequential dependency among stages. As a result, users must be sure each stage runs high-speed computations. 
\subsubsection{Dynamic Pipeline Paradigm}\label{sec:dp}
The \textit{Dynamic Pipeline Paradigm} (DPP) \cite{dpdef} is a \acrshort{pip} computational model based on a one-dimensional and unidirectional chain of stages connected by means of channels synchronized by data availability. 
This chain of stages is a computational structure called \textit{Dynamic Pipeline} ($\DP$). A $\DP$ stretches and shrinks depending on the spawning and the lifetime of its stages, respectively. Modeling an algorithmic 
solution as a $\DP$ corresponds to define a dynamic computational structure in terms of four kinds of stages: \textit{Source} ($\iwcc$), \textit{Generator} ($\gwcc$), \textit{Sink} ($\owcc$) and \textit{Filter} ($\fwcc$) stages. 
In particular, the specific behavior of each stage to solve a particular problem must be defined, as well as the number and the type of channels connecting them. Channels are unidirectional according to the flow of the data. 
The \textit{Generator} stage is in charge of spawning \textit{Filter} stage instances. This particular behavior of the \textit{Generator} gives the elastic capacity to DPs. \textit{Filter} stage instances are stateful operators in the 
sense described in \cite{hr19}, i.e., \textit{Filter} instances have a state.  
The deployment of a $\DP$ consists in setting up the initial configuration depicted in \autoref{fig:initialDP}. 
%\begin{wrapfigure}{r}{0.5\textwidth}
\begin{figure}[h]
\centering
\inputtikz{genericDP-Initial}
\caption[{[Pre] Initial configuration of a DP}]{ An initial DP consists of three stages: $\iwcc$, $\gwcc$ together its filter parameter $\fwcc$, and $\owcc$. These stages are connected through its channels --represented by right arrows-- as shown in this figure.}
\label{fig:initialDP}
\end{figure}
%\end{wrapfigure}
The activation of a $\DP$ starts when a stream of data items arrives at the initial configuration of the $\DP$. 
When a data stream arrives to the \textit{Source} stage. During the execution, the \textit{Generator} stage spawns \textit{Filter} stage instances according to incoming data and the \textit{Generator} defined behavior; \autoref{fig:activeDP} depicts this evolution. 
If the data stream is bounded, the computation ends when the lifetime of all the stages of $\DP$ has finished. Otherwise, if the stream data is unbounded, 
the $\DP$ remains active and results are output incrementally. 


\begin{figure}[h]
 \centering
 \inputtikz{genericDP-Evol}
 \caption[{[Pre] Evolution of DP}]{Evolution of a DP. After creating some filter instances (shadow Filter squares) of the filter parameter (light Filter square) in the Generator, the DP has stretched.}
\label{fig:activeDP}
\end{figure}

\iffalse
\subsubsection{Streaming in Haskell Language}
Streaming computational models have been implemented in \acrlong{hs} during the last $10$ years. One of the first libraries in the ecosystem was \mintinline{shell}{conduit}\footnote{\url{https://hackage.haskell.org/package/conduit}} in 2011.
After that, several efforts on improving streaming processing on the language has been made not only at abstraction level for the user but as well as performance execution 
improvements like \mintinline{shell}{pipes}~\footnote{\url{https://hackage.haskell.org/package/pipes}} and \mintinline{shell}{streamly}\footnote{\url{https://hackage.haskell.org/package/streamly}} lately.
Moreover, there is an empirical comparison between those three, where a benchmark analysis has been conducted~\cite{benchstreamhs}.

Although most of those libraries offer the ability to implement \acrshort{dap} and \acrshort{pip}, none of them provide clear abstractions to create \acrshort{dp} models because
the setup of the stages should be provided beforehand. In the context of this work, we have done a proof of concept at the beginning, 
but it was not possible to adapt any of those libraries to implement properly \acrshort{dp}. 
The closest we have been to implement \acrshort{dp} with some of those libraries was when we explored \mintinline{shell}{streamly}.
In this case, there is a \mintinline{haskell}{foldrS} combinator that could have been proper for the purpose of generating a dynamic pipeline of stages based on the data flow. However, it was not possible to manipulate the channels between the stages to control the flow of the data. It is important to remark that, even though, the  library  \mintinline{shell}{streamly} implements channels, they are hidden from the end-user, and there is not a  clear way to manipulate them.

To the best of our knowledge, no similar library under the  \acrshort{dp} approach has been written in \acrlong{hs}. 
One important motivation to develop our own framework is that  we not only  want to satisfy our research needs but, as a novel contribution, we aim at providing a \acrshort{dpf} to the \acrshort{hs} community as well. We hope this contribution encourages and helps writing algorithms under the Dynamic Pipeline Paradigm. 
\fi


\input{wcc}